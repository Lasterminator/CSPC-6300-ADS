{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc61693c-eb01-4127-aae2-0118abd1f6c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tpittal/.conda/envs/ads/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": false,\n",
      "  \"transformers_version\": \"4.47.0\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 1024,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"transformers_version\": \"4.47.0\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Wreckolas Edwards . Instead to pursue them'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "# load image from the IAM database\n",
    "url = 'text_blocks/text_block_12.png'\n",
    "image = Image.open(url).convert(\"RGB\")\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-large-handwritten')\n",
    "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-large-handwritten')\n",
    "pixel_values = processor(images=image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "57e93991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Using cached huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached huggingface_hub-0.26.3-py3-none-any.whl (447 kB)\n",
      "Using cached regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
      "Using cached safetensors-0.4.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (435 kB)\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.26.3 regex-2024.11.6 safetensors-0.4.5 tokenizers-0.21.0 transformers-4.47.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d36fde-7af8-4f6a-9a6f-2441f02321a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image split into 83 lines and saved to data/split_images/\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image\n",
    "input_path = \"dupickens_a-1_042_binary_otsu.png\"\n",
    "output_dir = \"data/split_images/\"  # Directory to save the split images\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Read the image\n",
    "image = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Apply binary thresholding\n",
    "_, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "# Sum pixel values along the horizontal axis to create a horizontal projection profile\n",
    "horizontal_projection = np.sum(binary_image, axis=1)\n",
    "\n",
    "# Detect regions with text based on the projection profile\n",
    "threshold = np.max(horizontal_projection) * 0.1  # Adjust sensitivity as needed\n",
    "line_indices = np.where(horizontal_projection > threshold)[0]\n",
    "\n",
    "# Group consecutive indices to detect lines\n",
    "lines = []\n",
    "current_line = [line_indices[0]]\n",
    "for i in range(1, len(line_indices)):\n",
    "    if line_indices[i] - line_indices[i - 1] > 1:  # New line detected\n",
    "        lines.append(current_line)\n",
    "        current_line = [line_indices[i]]\n",
    "    else:\n",
    "        current_line.append(line_indices[i])\n",
    "lines.append(current_line)\n",
    "\n",
    "# Crop and save each detected line\n",
    "for idx, line in enumerate(lines):\n",
    "    y_min = min(line)\n",
    "    y_max = max(line)\n",
    "    \n",
    "    # Add a small margin (optional)\n",
    "    margin = 5\n",
    "    y_min = max(0, y_min - margin)\n",
    "    y_max = min(image.shape[0], y_max + margin)\n",
    "    \n",
    "    # Crop the line\n",
    "    cropped_line = image[y_min:y_max, :]\n",
    "    \n",
    "    # Save the cropped line\n",
    "    line_path = os.path.join(output_dir, f\"line_{idx + 1}.png\")\n",
    "    cv2.imwrite(line_path, cropped_line)\n",
    "\n",
    "print(f\"Image split into {len(lines)} lines and saved to {output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea72f124-1512-4bb2-a7fd-ee235a2f4984",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config of the encoder: <class 'transformers.models.vit.modeling_vit.ViTModel'> is overwritten by shared encoder config: ViTConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"encoder_stride\": 16,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"image_size\": 384,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"model_type\": \"vit\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"patch_size\": 16,\n",
      "  \"qkv_bias\": false,\n",
      "  \"transformers_version\": \"4.46.2\"\n",
      "}\n",
      "\n",
      "Config of the decoder: <class 'transformers.models.trocr.modeling_trocr.TrOCRForCausalLM'> is overwritten by shared decoder config: TrOCRConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_cross_attention\": true,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"cross_attention_hidden_size\": 1024,\n",
      "  \"d_model\": 1024,\n",
      "  \"decoder_attention_heads\": 16,\n",
      "  \"decoder_ffn_dim\": 4096,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_decoder\": true,\n",
      "  \"layernorm_embedding\": true,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"trocr\",\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"transformers_version\": \"4.46.2\",\n",
      "  \"use_cache\": false,\n",
      "  \"use_learned_position_embeddings\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-large-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed dupickens_a-1_051_binary_otsu.png: 67 lines saved to processed_texts/dupickens_a-1_051_binary_otsu\n",
      "Processed dupickens_a-1_052_binary_otsu.png: 76 lines saved to processed_texts/dupickens_a-1_052_binary_otsu\n",
      "Processed dupickens_a-1_053_binary_otsu.png: 80 lines saved to processed_texts/dupickens_a-1_053_binary_otsu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "\n",
    "# Define directories\n",
    "input_dir = \"output/test\"  # Directory containing the original images\n",
    "output_dir = \"processed_texts\"  # Directory to save OCR results\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Load the TrOCR model and processor\n",
    "processor = TrOCRProcessor.from_pretrained('microsoft/trocr-large-handwritten')\n",
    "model = VisionEncoderDecoderModel.from_pretrained('microsoft/trocr-large-handwritten')\n",
    "\n",
    "# Filter files with '_binary_otsu.png' in their names\n",
    "input_files = [f for f in os.listdir(input_dir) if f.endswith('_binary_otsu.png')]\n",
    "\n",
    "# Process each image\n",
    "for input_file in input_files:\n",
    "    input_path = os.path.join(input_dir, input_file)\n",
    "    base_name = os.path.splitext(input_file)[0]  # e.g., dupickens_a-1_011\n",
    "    image_output_dir = os.path.join(output_dir, base_name)  # Create a folder for this image's text\n",
    "    os.makedirs(image_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Read the image\n",
    "    image = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Apply binary thresholding\n",
    "    _, binary_image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Sum pixel values along the horizontal axis to create a horizontal projection profile\n",
    "    horizontal_projection = np.sum(binary_image, axis=1)\n",
    "    \n",
    "    # Detect regions with text based on the projection profile\n",
    "    threshold = np.max(horizontal_projection) * 0.1  # Adjust sensitivity as needed\n",
    "    line_indices = np.where(horizontal_projection > threshold)[0]\n",
    "    \n",
    "    # Group consecutive indices to detect lines\n",
    "    lines = []\n",
    "    current_line = [line_indices[0]]\n",
    "    for i in range(1, len(line_indices)):\n",
    "        if line_indices[i] - line_indices[i - 1] > 1:  # New line detected\n",
    "            lines.append(current_line)\n",
    "            current_line = [line_indices[i]]\n",
    "        else:\n",
    "            current_line.append(line_indices[i])\n",
    "    lines.append(current_line)\n",
    "    \n",
    "    # Process each detected line\n",
    "    for idx, line in enumerate(lines):\n",
    "        y_min = min(line)\n",
    "        y_max = max(line)\n",
    "        \n",
    "        # Add a small margin (optional)\n",
    "        margin = 5\n",
    "        y_min = max(0, y_min - margin)\n",
    "        y_max = min(image.shape[0], y_max + margin)\n",
    "        \n",
    "        # Crop the line\n",
    "        cropped_line = image[y_min:y_max, :]\n",
    "        \n",
    "        # Save the cropped line temporarily\n",
    "        temp_line_path = f\"{image_output_dir}/line_{idx + 1}.png\"\n",
    "        cv2.imwrite(temp_line_path, cropped_line)\n",
    "        \n",
    "        # OCR Processing\n",
    "        line_image = Image.open(temp_line_path).convert(\"RGB\")\n",
    "        pixel_values = processor(images=line_image, return_tensors=\"pt\").pixel_values\n",
    "        generated_ids = model.generate(pixel_values)\n",
    "        generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        \n",
    "        # Save OCR text for this line\n",
    "        line_text_path = os.path.join(image_output_dir, f\"line_{idx + 1}.txt\")\n",
    "        with open(line_text_path, 'w') as text_file:\n",
    "            text_file.write(generated_text)\n",
    "    \n",
    "    print(f\"Processed {input_file}: {len(lines)} lines saved to {image_output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de7ceae6-5b20-42e1-ac5c-6e07cb57b5a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (0.19.1)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from torch) (1.13.2)\n",
      "Requirement already satisfied: networkx in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from torchvision) (2.0.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Using cached opencv_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (62.5 MB)\n",
      "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
      "Installing collected packages: opencv-python, fsspec\n",
      "Successfully installed fsspec-2024.10.0 opencv-python-4.10.0.84\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision opencv-python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d715285a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting paddleocr\n",
      "  Using cached paddleocr-2.9.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting paddlepaddle-gpu\n",
      "  Downloading paddlepaddle_gpu-2.6.2-cp310-cp310-manylinux1_x86_64.whl.metadata (8.6 kB)\n",
      "Collecting shapely (from paddleocr)\n",
      "  Using cached shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting scikit-image (from paddleocr)\n",
      "  Using cached scikit_image-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting imgaug (from paddleocr)\n",
      "  Using cached imgaug-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting pyclipper (from paddleocr)\n",
      "  Using cached pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting lmdb (from paddleocr)\n",
      "  Using cached lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting tqdm (from paddleocr)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting numpy<2.0 (from paddleocr)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting rapidfuzz (from paddleocr)\n",
      "  Using cached rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: opencv-python in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from paddleocr) (4.10.0.84)\n",
      "Collecting opencv-contrib-python (from paddleocr)\n",
      "  Using cached opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting cython (from paddleocr)\n",
      "  Using cached Cython-3.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: Pillow in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from paddleocr) (10.4.0)\n",
      "Requirement already satisfied: pyyaml in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from paddleocr) (6.0.1)\n",
      "Collecting python-docx (from paddleocr)\n",
      "  Using cached python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting beautifulsoup4 (from paddleocr)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.24.0 (from paddleocr)\n",
      "  Downloading fonttools-4.55.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (164 kB)\n",
      "Collecting fire>=0.3.0 (from paddleocr)\n",
      "  Using cached fire-0.7.0-py3-none-any.whl\n",
      "Requirement already satisfied: requests in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from paddleocr) (2.32.3)\n",
      "Collecting albumentations==1.4.10 (from paddleocr)\n",
      "  Using cached albumentations-1.4.10-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting albucore==0.0.13 (from paddleocr)\n",
      "  Using cached albucore-0.0.13-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting tomli>=2.0.1 (from albucore==0.0.13->paddleocr)\n",
      "  Downloading tomli-2.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from albucore==0.0.13->paddleocr) (4.11.0)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albucore==0.0.13->paddleocr)\n",
      "  Using cached opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting scipy>=1.10.0 (from albumentations==1.4.10->paddleocr)\n",
      "  Using cached scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Collecting scikit-learn>=1.3.2 (from albumentations==1.4.10->paddleocr)\n",
      "  Using cached scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting pydantic>=2.7.0 (from albumentations==1.4.10->paddleocr)\n",
      "  Downloading pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
      "Collecting httpx (from paddlepaddle-gpu)\n",
      "  Downloading httpx-0.28.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: decorator in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from paddlepaddle-gpu) (5.1.1)\n",
      "Collecting astor (from paddlepaddle-gpu)\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting opt-einsum==3.3.0 (from paddlepaddle-gpu)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting protobuf>=3.20.2 (from paddlepaddle-gpu)\n",
      "  Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting termcolor (from fire>=0.3.0->paddleocr)\n",
      "  Using cached termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from scikit-image->paddleocr) (3.2.1)\n",
      "Collecting imageio>=2.33 (from scikit-image->paddleocr)\n",
      "  Downloading imageio-2.36.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image->paddleocr)\n",
      "  Using cached tifffile-2024.9.20-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: packaging>=21 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from scikit-image->paddleocr) (24.2)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image->paddleocr)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->paddleocr)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting anyio (from httpx->paddlepaddle-gpu)\n",
      "  Downloading anyio-4.7.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: certifi in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from httpx->paddlepaddle-gpu) (2024.8.30)\n",
      "Collecting httpcore==1.* (from httpx->paddlepaddle-gpu)\n",
      "  Downloading httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: idna in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from httpx->paddlepaddle-gpu) (3.7)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->paddlepaddle-gpu)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Requirement already satisfied: six in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from imgaug->paddleocr) (1.17.0)\n",
      "Collecting matplotlib (from imgaug->paddleocr)\n",
      "  Downloading matplotlib-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting lxml>=3.1.0 (from python-docx->paddleocr)\n",
      "  Using cached lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from requests->paddleocr) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from requests->paddleocr) (2.2.3)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.7.0->albumentations==1.4.10->paddleocr)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.1 (from pydantic>=2.7.0->albumentations==1.4.10->paddleocr)\n",
      "  Downloading pydantic_core-2.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting typing-extensions>=4.9.0 (from albucore==0.0.13->paddleocr)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn>=1.3.2->albumentations==1.4.10->paddleocr)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.3.2->albumentations==1.4.10->paddleocr)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from anyio->httpx->paddlepaddle-gpu) (1.2.2)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx->paddlepaddle-gpu)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->imgaug->paddleocr)\n",
      "  Using cached contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->imgaug->paddleocr)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->imgaug->paddleocr)\n",
      "  Using cached kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->imgaug->paddleocr)\n",
      "  Using cached pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/tpittal/.conda/envs/ads/lib/python3.10/site-packages (from matplotlib->imgaug->paddleocr) (2.9.0.post0)\n",
      "Using cached paddleocr-2.9.1-py3-none-any.whl (544 kB)\n",
      "Using cached albucore-0.0.13-py3-none-any.whl (8.5 kB)\n",
      "Using cached albumentations-1.4.10-py3-none-any.whl (161 kB)\n",
      "Downloading paddlepaddle_gpu-2.6.2-cp310-cp310-manylinux1_x86_64.whl (758.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m758.9/758.9 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Downloading fonttools-4.55.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Downloading protobuf-5.29.1-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Using cached scikit_image-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
      "Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached Cython-3.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Downloading httpx-0.28.0-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Using cached imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "Using cached lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\n",
      "Using cached opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68.7 MB)\n",
      "Using cached pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (912 kB)\n",
      "Using cached python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
      "Using cached rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached shapely-2.0.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading imageio-2.36.1-py3-none-any.whl (315 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached lxml-5.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "Using cached opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "Downloading pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
      "Downloading pydantic_core-2.27.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached scikit_learn-1.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "Using cached scipy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.2 MB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Using cached tifffile-2024.9.20-py3-none-any.whl (228 kB)\n",
      "Downloading tomli-2.2.1-py3-none-any.whl (14 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading anyio-4.7.0-py3-none-any.whl (93 kB)\n",
      "Downloading matplotlib-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "Using cached pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: pyclipper, lmdb, typing-extensions, tqdm, tomli, threadpoolctl, termcolor, soupsieve, sniffio, rapidfuzz, pyparsing, protobuf, numpy, lxml, lazy-loader, kiwisolver, joblib, h11, fonttools, cython, cycler, astor, annotated-types, tifffile, shapely, scipy, python-docx, pydantic-core, opt-einsum, opencv-python-headless, opencv-contrib-python, imageio, httpcore, fire, contourpy, beautifulsoup4, anyio, scikit-learn, scikit-image, pydantic, matplotlib, httpx, albucore, paddlepaddle-gpu, imgaug, albumentations, paddleocr\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.11.0\n",
      "    Uninstalling typing_extensions-4.11.0:\n",
      "      Successfully uninstalled typing_extensions-4.11.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.1\n",
      "    Uninstalling numpy-2.0.1:\n",
      "      Successfully uninstalled numpy-2.0.1\n",
      "Successfully installed albucore-0.0.13 albumentations-1.4.10 annotated-types-0.7.0 anyio-4.7.0 astor-0.8.1 beautifulsoup4-4.12.3 contourpy-1.3.1 cycler-0.12.1 cython-3.0.11 fire-0.7.0 fonttools-4.55.2 h11-0.14.0 httpcore-1.0.7 httpx-0.28.0 imageio-2.36.1 imgaug-0.4.0 joblib-1.4.2 kiwisolver-1.4.7 lazy-loader-0.4 lmdb-1.5.1 lxml-5.3.0 matplotlib-3.9.3 numpy-1.26.4 opencv-contrib-python-4.10.0.84 opencv-python-headless-4.10.0.84 opt-einsum-3.3.0 paddleocr-2.9.1 paddlepaddle-gpu-2.6.2 protobuf-5.29.1 pyclipper-1.3.0.post6 pydantic-2.10.3 pydantic-core-2.27.1 pyparsing-3.2.0 python-docx-1.1.2 rapidfuzz-3.10.1 scikit-image-0.24.0 scikit-learn-1.5.2 scipy-1.14.1 shapely-2.0.6 sniffio-1.3.1 soupsieve-2.6 termcolor-2.5.0 threadpoolctl-3.5.0 tifffile-2024.9.20 tomli-2.2.1 tqdm-4.67.1 typing-extensions-4.12.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install paddleocr paddlepaddle-gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7532b51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/12/05 23:36:29] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='path_to_dbnet++_det_model', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/home/tpittal/.paddleocr/whl/rec/ch/ch_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/home/tpittal/.conda/envs/ads/lib/python3.10/site-packages/paddleocr/ppocr/utils/ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='/home/tpittal/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2024/12/05 23:36:29] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39m# Save and display the result\u001b[39;00m\n\u001b[1;32m     22\u001b[0m result_image_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdetected_text_result.jpg\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 23\u001b[0m image_with_boxes\u001b[39m.\u001b[39;49msave(result_image_path)\n\u001b[1;32m     24\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDetection result saved at \u001b[39m\u001b[39m{\u001b[39;00mresult_image_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR, draw_ocr\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Initialize PaddleOCR with the DBNet++ detection model\n",
    "ocr = PaddleOCR(det_model_dir='path_to_dbnet++_det_model', use_gpu=False)\n",
    "\n",
    "# Path to input image\n",
    "image_path = \"dupickens_a-1_041_original.png\"\n",
    "\n",
    "# Run OCR for text detection\n",
    "results = ocr.ocr(image_path, det=True, rec=False)\n",
    "\n",
    "# Load image for visualization\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "boxes = [line[0] for line in results[0]]\n",
    "\n",
    "# Draw detected text boxes on the image\n",
    "image_with_boxes = draw_ocr(image, boxes, txts=None, scores=None, font_path='path_to_font.ttf')\n",
    "\n",
    "# Save and display the result\n",
    "result_image_path = \"detected_text_result.jpg\"\n",
    "image_with_boxes.save(result_image_path)\n",
    "print(f\"Detection result saved at {result_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "173a8d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/12/05 23:43:25] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='path_to_dbnet++_det_model', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.1, det_db_unclip_ratio=3, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/home/tpittal/.paddleocr/whl/rec/ch/ch_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/home/tpittal/.conda/envs/ads/lib/python3.10/site-packages/paddleocr/ppocr/utils/ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=False, cls_model_dir='/home/tpittal/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2024/12/05 23:43:25] ppocr WARNING: Since the angle classifier is not initialized, it will not be used during the forward process\n",
      "[2024/12/05 23:43:25] ppocr DEBUG: dt_boxes num : 104, elapsed : 0.21836161613464355\n",
      "[2024/12/05 23:43:28] ppocr DEBUG: rec_res num  : 104, elapsed : 2.0539913177490234\n",
      "Detection result saved at detected_text_result.jpg\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR, draw_ocr\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "# Initialize PaddleOCR with the DBNet++ detection model\n",
    "ocr = PaddleOCR(\n",
    "    det_model_dir='path_to_dbnet++_det_model',\n",
    "    det_db_box_thresh=0.1,  # Lower the box threshold to detect faint text\n",
    "    det_db_unclip_ratio=3,  # Increase unclip ratio to detect tightly packed text\n",
    "    use_gpu=False\n",
    "    )\n",
    "\n",
    "# Path to input image\n",
    "image_path = \"dupickens_a-1_042_binary_otsu.png\"\n",
    "\n",
    "# Run OCR for text detection\n",
    "results = ocr.ocr(image_path, det=True, rec=True)\n",
    "\n",
    "# Load image for visualization\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "boxes = [line[0] for line in results[0]]\n",
    "\n",
    "# Draw detected text boxes on the image\n",
    "image_with_boxes = draw_ocr(image, boxes, txts=None, scores=None, font_path='path_to_font.ttf')\n",
    "\n",
    "# Convert the numpy.ndarray result to a Pillow Image\n",
    "image_with_boxes = Image.fromarray(image_with_boxes)\n",
    "\n",
    "# Save and display the result\n",
    "result_image_path = \"detected_text_result.jpg\"\n",
    "image_with_boxes.save(result_image_path)\n",
    "print(f\"Detection result saved at {result_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86363fd9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
