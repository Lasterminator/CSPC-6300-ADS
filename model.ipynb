{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import cv2\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HandwritingDataset(Dataset):\n",
    "    def __init__(self, image_dir, annotations_file, max_length=128):\n",
    "        self.image_dir = image_dir\n",
    "        self.max_length = max_length\n",
    "\n",
    "        with open(annotations_file, 'r') as f:\n",
    "            self.annotations = json.load(f)\n",
    "\n",
    "        self.data = [\n",
    "            item for item in self.annotations \n",
    "            if item['status'] == 'success' and len(item['text'].strip()) > 0\n",
    "        ]\n",
    "\n",
    "        self.create_char_mappings()\n",
    "        \n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406],\n",
    "                std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ])\n",
    "\n",
    "    def create_char_mappings(self):\n",
    "        all_chars = set()\n",
    "        for item in self.data:\n",
    "            all_chars.update(item['text'])\n",
    "            \n",
    "\n",
    "        self.char_to_idx = {char: idx + 1 for idx, char in enumerate(sorted(all_chars))}\n",
    "        self.char_to_idx['<pad>'] = 0\n",
    "        self.idx_to_char = {idx: char for char, idx in self.char_to_idx.items()}\n",
    "        self.vocab_size = len(self.char_to_idx)\n",
    "        \n",
    "        print(f\"Vocabulary size: {self.vocab_size}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        \n",
    "        # Load image\n",
    "        image_path = os.path.join(\n",
    "            self.image_dir,\n",
    "            f\"{os.path.splitext(item['filename'])[0]}_binary_adaptive.png\"\n",
    "        )\n",
    "        image = cv2.imread(image_path)\n",
    "        \n",
    "        if image is None:\n",
    "            raise ValueError(f\"Could not load image: {image_path}\")\n",
    "            \n",
    "        if len(image.shape) == 2:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "            \n",
    "   \n",
    "        image = self.transform(image)\n",
    "        text = item['text'][:self.max_length]\n",
    "        text_indices = [self.char_to_idx[c] for c in text]\n",
    "        \n",
    "\n",
    "        if len(text_indices) < self.max_length:\n",
    "            text_indices.extend([0] * (self.max_length - len(text_indices)))\n",
    "            \n",
    "        return {\n",
    "            'image': image,\n",
    "            'text': torch.tensor(text_indices, dtype=torch.long),\n",
    "            'length': len(text)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HandwritingRecognitionModel(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size=256, sequence_length=128):\n",
    "        super().__init__()\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "        self.cnn = resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "        self.cnn.fc = nn.Identity()\n",
    "        \n",
    "        self.feature_processor = nn.Sequential(\n",
    "            nn.Linear(512, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        \n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=2,\n",
    "            bidirectional=True,\n",
    "            batch_first=True\n",
    "        )\n",
    "        \n",
    "\n",
    "        self.fc = nn.Linear(hidden_size * 2, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        features = self.cnn(x)\n",
    "        \n",
    "\n",
    "        features = self.feature_processor(features)\n",
    "        \n",
    "\n",
    "        features = features.unsqueeze(1).repeat(1, self.sequence_length, 1)\n",
    "\n",
    "        rnn_out, _ = self.rnn(features)\n",
    "        \n",
    "        logits = self.fc(rnn_out)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with tqdm(train_loader, desc='Training') as pbar:\n",
    "        for batch in pbar:\n",
    "            images = batch['image'].to(device)\n",
    "            texts = batch['text'].to(device)   \n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(images)\n",
    "            \n",
    "            # Reshape for loss calculation\n",
    "            B, S, V = logits.shape\n",
    "            loss = criterion(\n",
    "                logits.view(B * S, V),\n",
    "                texts.view(-1)              )\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "            \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            texts = batch['text'].to(device)\n",
    "            \n",
    "            logits = model(images)\n",
    "            B, S, V = logits.shape\n",
    "            loss = criterion(\n",
    "                logits.view(B * S, V),\n",
    "                texts.view(-1)\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "def decode_prediction(logits, idx_to_char):\n",
    "    \"\"\"Decode model predictions to text\"\"\"\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    decoded_texts = []\n",
    "    \n",
    "    for pred in predictions:\n",
    "        text = ''.join([idx_to_char[idx.item()] for idx in pred if idx.item() != 0])\n",
    "        decoded_texts.append(text)\n",
    "    \n",
    "    return decoded_texts\n",
    "\n",
    "def main():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    data_dir = \"output\"\n",
    "    image_dir = os.path.join(data_dir, \"processed_images\")\n",
    "    annotations_file = os.path.join(data_dir, \"ocr/detailed_results.json\")\n",
    "    \n",
    "    dataset = HandwritingDataset(image_dir, annotations_file)\n",
    "    print(f\"Total samples: {len(dataset)}\")\n",
    "    \n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = torch.utils.data.random_split(\n",
    "        dataset, [train_size, val_size]\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=True,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    model = HandwritingRecognitionModel(\n",
    "        vocab_size=dataset.vocab_size,\n",
    "        sequence_length=dataset.max_length\n",
    "    ).to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, mode='min', factor=0.5, patience=2, verbose=True\n",
    "    )\n",
    "    \n",
    "    num_epochs = 10\n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        \n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        val_loss = validate(model, val_loader, criterion, device)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}\")\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_loss': val_loss,\n",
    "                'char_to_idx': dataset.char_to_idx,\n",
    "                'idx_to_char': dataset.idx_to_char\n",
    "            }, 'best_model.pth')\n",
    "            print(\"Saved best model\")\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                model.eval()\n",
    "                batch = next(iter(val_loader))\n",
    "                images = batch['image'].to(device)\n",
    "                logits = model(images)\n",
    "                predictions = decode_prediction(logits, dataset.idx_to_char)\n",
    "                print(\"\\nSample Predictions:\")\n",
    "                for i, pred in enumerate(predictions[:3]):  # Show first 3 predictions\n",
    "                    print(f\"Predicted: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Vocabulary size: 112\n",
      "Total samples: 427\n",
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  41%|████      | 9/22 [00:13<00:18,  1.46s/it, loss=2.75]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import Levenshtein\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import os\n",
    "\n",
    "class ModelAnalyzer:\n",
    "    def __init__(self, model_path, test_loader, device, idx_to_char):\n",
    "        \"\"\"\n",
    "        Initialize the analyzer with model and data\n",
    "        \"\"\"\n",
    "        self.checkpoint = torch.load(model_path)\n",
    "        self.model = HandwritingRecognitionModel(\n",
    "            vocab_size=len(idx_to_char),\n",
    "            sequence_length=128\n",
    "        ).to(device)\n",
    "        self.model.load_state_dict(self.checkpoint['model_state_dict'])\n",
    "        self.model.eval()\n",
    "        \n",
    "        self.test_loader = test_loader\n",
    "        self.device = device\n",
    "        self.idx_to_char = idx_to_char\n",
    "        \n",
    "    def decode_text(self, tensor):\n",
    "        \"\"\"Convert tensor predictions to text\"\"\"\n",
    "        indices = tensor.argmax(dim=-1)\n",
    "        text = ''.join([self.idx_to_char[idx.item()] for idx in indices if idx.item() != 0])\n",
    "        return text\n",
    "        \n",
    "    def calculate_text_metrics(self, pred_text, true_text):\n",
    "        \"\"\"Calculate various text similarity metrics\"\"\"\n",
    "        return {\n",
    "            'levenshtein_distance': Levenshtein.distance(pred_text, true_text),\n",
    "            'similarity_ratio': Levenshtein.ratio(pred_text, true_text),\n",
    "            'length_diff': abs(len(pred_text) - len(true_text)),\n",
    "            'exact_match': pred_text == true_text\n",
    "        }\n",
    "        \n",
    "    def analyze_model_performance(self):\n",
    "        \"\"\"Perform comprehensive model analysis\"\"\"\n",
    "        results = []\n",
    "        character_errors = defaultdict(int)\n",
    "        total_chars = 0\n",
    "        correct_chars = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.test_loader, desc=\"Analyzing performance\"):\n",
    "                images = batch['image'].to(self.device)\n",
    "                true_texts = batch['text']\n",
    "                \n",
    "                logits = self.model(images)\n",
    "                \n",
    "                for i in range(len(images)):\n",
    "                    pred_text = self.decode_text(logits[i])\n",
    "                    true_text = ''.join([self.idx_to_char[idx.item()] \n",
    "                                       for idx in true_texts[i] if idx.item() != 0])\n",
    "                    \n",
    "                    metrics = self.calculate_text_metrics(pred_text, true_text)\n",
    "                    \n",
    "                    for pred_char, true_char in zip(pred_text, true_text):\n",
    "                        total_chars += 1\n",
    "                        if pred_char == true_char:\n",
    "                            correct_chars += 1\n",
    "                        else:\n",
    "                            character_errors[f\"{true_char}->{pred_char}\"] += 1\n",
    "                    \n",
    "                    results.append({\n",
    "                        'predicted_text': pred_text,\n",
    "                        'true_text': true_text,\n",
    "                        'text_length': len(true_text),\n",
    "                        **metrics\n",
    "                    })\n",
    "        \n",
    "        return pd.DataFrame(results), character_errors, correct_chars/total_chars\n",
    "\n",
    "    def generate_analysis_report(self, save_dir='analysis_results'):\n",
    "        \"\"\"Generate comprehensive analysis report with visualizations\"\"\"\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        print(\"Analyzing model performance...\")\n",
    "        results_df, char_errors, char_accuracy = self.analyze_model_performance()\n",
    "        \n",
    "        basic_stats = {\n",
    "            'Total Samples': len(results_df),\n",
    "            'Average Levenshtein Distance': results_df['levenshtein_distance'].mean(),\n",
    "            'Average Similarity Ratio': results_df['similarity_ratio'].mean(),\n",
    "            'Exact Match Rate': results_df['exact_match'].mean(),\n",
    "            'Character Accuracy': char_accuracy\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(save_dir, 'basic_stats.json'), 'w') as f:\n",
    "            json.dump(basic_stats, f, indent=4)\n",
    "        \n",
    "        plt.figure(figsize=(15, 10))\n",
    "        \n",
    "        plt.subplot(2, 2, 1)\n",
    "        sns.histplot(data=results_df, x='levenshtein_distance', bins=30)\n",
    "        plt.title('Distribution of Levenshtein Distances')\n",
    "        \n",
    "        plt.subplot(2, 2, 2)\n",
    "        sns.scatterplot(data=results_df, x='text_length', y='similarity_ratio')\n",
    "        plt.title('Text Length vs Similarity Ratio')\n",
    "        \n",
    "        plt.subplot(2, 2, 3)\n",
    "        char_errors_df = pd.DataFrame(\n",
    "            list(char_errors.items()),\n",
    "            columns=['Error_Type', 'Count']\n",
    "        ).sort_values('Count', ascending=False).head(10)\n",
    "        \n",
    "        sns.barplot(data=char_errors_df, x='Error_Type', y='Count')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title('Top 10 Character Error Types')\n",
    "        \n",
    "        plt.subplot(2, 2, 4)\n",
    "        sns.histplot(data=results_df, x='length_diff', bins=20)\n",
    "        plt.title('Distribution of Length Differences')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(save_dir, 'analysis_plots.png'))\n",
    "        plt.close()\n",
    "        \n",
    "        error_analysis = results_df[results_df['exact_match'] == False].copy()\n",
    "        error_analysis['error_type'] = error_analysis.apply(\n",
    "            lambda x: self.categorize_error(x['predicted_text'], x['true_text']),\n",
    "            axis=1\n",
    "        )\n",
    "        \n",
    "        error_summary = error_analysis['error_type'].value_counts()\n",
    "        error_summary.to_csv(os.path.join(save_dir, 'error_types.csv'))\n",
    "        \n",
    "        examples = results_df.sort_values('similarity_ratio')\n",
    "        worst_examples = examples.head(10)\n",
    "        best_examples = examples.tail(10)\n",
    "        \n",
    "        examples_report = {\n",
    "            'worst_cases': worst_examples.to_dict('records'),\n",
    "            'best_cases': best_examples.to_dict('records')\n",
    "        }\n",
    "        \n",
    "        with open(os.path.join(save_dir, 'example_cases.json'), 'w') as f:\n",
    "            json.dump(examples_report, f, indent=4)\n",
    "        \n",
    "        return basic_stats, results_df\n",
    "    \n",
    "    def categorize_error(self, pred, true):\n",
    "        \"\"\"Categorize the type of error\"\"\"\n",
    "        if len(pred) > len(true):\n",
    "            return 'insertion'\n",
    "        elif len(pred) < len(true):\n",
    "            return 'deletion'\n",
    "        else:\n",
    "            return 'substitution'\n",
    "\n",
    "def analyze_model_results():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model_path = 'best_model.pth'\n",
    "    \n",
    "    test_dataset = HandwritingDataset(\n",
    "        image_dir=\"output/processed_images\",\n",
    "        annotations_file=\"output/ocr/detailed_results.json\"\n",
    "    )\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=16,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "    \n",
    "    analyzer = ModelAnalyzer(\n",
    "        model_path=model_path,\n",
    "        test_loader=test_loader,\n",
    "        device=device,\n",
    "        idx_to_char=test_dataset.idx_to_char\n",
    "    )\n",
    "    \n",
    "    print(\"Generating analysis report...\")\n",
    "    stats, results = analyzer.generate_analysis_report()\n",
    "    \n",
    "    print(\"\\nModel Performance Summary:\")\n",
    "    print(\"-\" * 50)\n",
    "    for key, value in stats.items():\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "    \n",
    "    print(\"\\nDetailed results saved in 'analysis_results' directory\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    analyze_model_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
